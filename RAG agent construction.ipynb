{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7935f9f",
   "metadata": {},
   "source": [
    "In our project we choose to use Nvidia_api for functionality, you can easily get an nvidia_api_key for AI foundation models in https://org.ngc.nvidia.com/setup/personal-keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9432d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints._common import NVEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd50a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA API Key: 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\n",
      "Retrieved NVIDIA_API_KEY beginning with \"nvapi--ws...\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to retrieve NVIDIA API key\n",
    "def retrieve_nvidia_api_key():\n",
    "    api_key = os.environ.get(\"NVIDIA_API_KEY\")\n",
    "    if api_key and \"nvapi-\" in api_key:\n",
    "        return api_key\n",
    "\n",
    "    hard_reset = False  # Set to True if you want to reset your NVIDIA_API_KEY\n",
    "    while not api_key or \"nvapi-\" not in api_key or hard_reset:\n",
    "        try:\n",
    "            assert not hard_reset\n",
    "            api_key_input = input(\"NVIDIA API Key: \")\n",
    "            assert api_key_input.startswith('nvapi-')\n",
    "            api_key = api_key_input\n",
    "        except:\n",
    "            print(\"[!] API key assignment failed. Make sure it starts with `nvapi-` as generated from the model pages.\")\n",
    "        hard_reset = False\n",
    "\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = api_key\n",
    "    return api_key\n",
    "\n",
    "# Retrieve NVIDIA API key\n",
    "api_key = retrieve_nvidia_api_key()\n",
    "print(f\"Retrieved NVIDIA_API_KEY beginning with \\\"{api_key[:9]}...\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bece8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'playground_llama2_code_34b': 'df2bee43-fb69-42b9-9ee5-f4eabbeaf3a8',\n",
       " 'ai-codellama-70b': 'f6b06895-d073-4714-8bb2-26c09e9f6597',\n",
       " 'ai-sdxl-turbo': 'f886140c-424e-4c82-a841-99e23f9ae35d',\n",
       " 'playground_cuopt': '8f2fbd00-2633-41ce-ab4e-e5736d74bff7',\n",
       " 'ai-ai-weather-forecasting': '9cec444c-db1c-4525-9c6f-f40e4a5b11ce',\n",
       " 'ai-stable-video-diffusion': '8cd594f1-6a4d-4f8f-82b4-d1bf89adae98',\n",
       " 'ai-example': '80a5d6c6-7658-49c5-b2b0-105bfb210282',\n",
       " 'playground_llama2_13b': 'e0bb7fb9-5333-4a27-8534-c6288f921d3f',\n",
       " 'ai-fuyu-8b': 'e598bfc1-b058-41af-869d-556d3c7e1b48',\n",
       " 'ai-esmfold': 'a68c59e0-47a6-4a50-bf64-6d88766d56bf',\n",
       " 'ai-mixtral-8x22b': '39655fc1-9ebc-4b24-963e-6915ea6680de',\n",
       " 'playground_starcoder2_15b': '6acada03-fe2f-4e4d-9e0a-e711b9fd1b59',\n",
       " 'ai-phi-3-mini-4k': 'ad974453-80d4-46df-a02d-6f7dae20c010',\n",
       " 'ai-mixtral-8x22b-instruct': '710c92d0-7c98-46d6-b5ae-07e84bcaa5d3',\n",
       " 'playground_mamba_chat': '381be320-4721-4664-bd75-58f8783b43c7',\n",
       " 'ai-nvidia-cuopt': 'b0ac1378-3d00-43cb-a8d9-0f0c37ef36c0',\n",
       " 'ai-vista-3d': '72311276-923f-4478-a506-d5b80914728a',\n",
       " 'ai-embed-qa-4': '09c64e32-2b65-4892-a285-2f585408d118',\n",
       " 'ai-mixtral-8x7b-instruct': 'a1e53ece-bff4-44d1-8b13-c009e5bf47f6',\n",
       " 'ai-llama2-70b': '2fddadfb-7e76-4c8a-9b82-f7d3fab94471',\n",
       " 'ai-recurrentgemma-2b': '2f495340-a99f-4b4b-89bd-1beb003dd896',\n",
       " 'playground_mistral_7b': '35ec3354-2681-4d0e-a8dd-80325dcf7c63',\n",
       " 'ai-arctic-embed-l': '1528a0ad-205a-46ac-a783-94e2372586a9',\n",
       " 'playground_llama2_code_70b': '2ae529dc-f728-4a46-9b8d-2697213666d8',\n",
       " 'playground_fuyu_8b': '9f757064-657f-4c85-abd7-37a7a9b6ee11',\n",
       " 'ai-parakeet-ctc-riva': '22164014-a6cc-4a6f-b048-f3a303e745bb',\n",
       " 'ai-microsoft-kosmos-2': '6018fed7-f227-48dc-99bc-3fd4264d5037',\n",
       " 'ai-diffdock': 'f3dda972-561a-4772-8c09-873594b6fb72',\n",
       " 'ai-llama3-8b': 'a5a3ad64-ec2c-4bfc-8ef7-5636f26630fe',\n",
       " 'playground_gemma_7b': '1361fa56-61d7-4a12-af32-69a3825746fa',\n",
       " 'ai-rerank-qa-mistral-4b': '0bf77f50-5c35-4488-8e7a-f49bb1974af6',\n",
       " 'ai-codegemma-7b': '7dfc10a8-3cc4-448e-97c1-2213308dc222',\n",
       " 'ai-mistral-large': '767b5b9a-3f9d-4c1d-86e8-fa861988cee7',\n",
       " 'ai-gemma-2b': '04174188-f742-4069-9e72-d77c2b77d3cb',\n",
       " 'playground_phi2': '6251d6d2-54ee-4486-90f4-2792bf0d3acd',\n",
       " 'playground_kosmos_2': '0bcd1a8c-451f-4b12-b7f0-64b4781190d1',\n",
       " 'playground_nv_llama2_rlhf_70b': '7b3e3361-4266-41c8-b312-f5e33c81fc92',\n",
       " 'ai-neva-22b': 'bc205f8e-1740-40df-8d32-c4321763498a',\n",
       " 'playground_sdxl': '89848fb8-549f-41bb-88cb-95d6597044a4',\n",
       " 'playground_mixtral_8x7b': '8f4118ba-60a8-4e6b-8574-e38a4067a4a3',\n",
       " 'playground_clip': '8c21289c-0b18-446d-8838-011b7249c513',\n",
       " 'ai-dbrx-instruct': '3d6c2ff8-8bfc-4d10-8fd0-b7337288e869',\n",
       " 'playground_deplot': '3bc390c7-eeec-40f7-a64d-0c6a719985f7',\n",
       " 'ai-google-deplot': '784a8ca4-ea7d-4c93-bb46-ec027c3fae47',\n",
       " 'playground_nemotron_steerlm_8b': '1423ff2f-d1c7-4061-82a7-9e8c67afd43a',\n",
       " 'playground_smaug_72b': '008cff6d-4f4c-4514-b61e-bcfad6ba52a7',\n",
       " 'playground_steerlm_llama_70b': 'd6fe6881-973a-4279-a0f8-e1d486c9618d',\n",
       " 'playground_yi_34b': '347fa3f3-d675-432c-b844-669ef8ee53df',\n",
       " 'playground_gemma_2b': '5bde8f6f-7e83-4413-a0f2-7b97be33988e',\n",
       " 'playground_seamless': '72ad9555-2e3d-4e73-9050-a37129064743',\n",
       " 'ai-mistral-7b-instruct-v2': 'd7618e99-db93-4465-af4d-330213a7f51f',\n",
       " 'ai-arctic': '7408b6b5-09e7-4ae5-a3fe-2db063e4e609',\n",
       " 'ai-llama3-70b': 'a88f115a-4a47-4381-ad62-ca25dc33dc1b',\n",
       " 'playground_llama2_code_13b': 'f6a96af4-8bf9-4294-96d6-d71aa787612e',\n",
       " 'playground_nvolveqa_40k': '091a03bb-7364-4087-8090-bd71e9277520',\n",
       " 'ai-phi-3-mini': '4a58c6cb-a9b4-4014-99de-3e704d4ae687',\n",
       " 'playground_llama2_70b': '0e349b44-440a-44e1-93e9-abe8dcb27158',\n",
       " 'ai-molmim-generate': '72be0b68-179f-412c-ac03-9a481f78cb9f',\n",
       " 'ai-stable-diffusion-xl': 'c1b63bb0-448b-4e53-b2a7-fb0b3723cbe2',\n",
       " 'playground_llama_guard': 'b34280ac-24e4-4081-bfaa-501e9ee16b6f',\n",
       " 'ai-gemma-7b': 'a13e3bed-ca42-48f8-b3f1-fbc47b9675f9',\n",
       " 'playground_neva_22b': '8bf70738-59b9-4e5f-bc87-7ab4203be7a0',\n",
       " 'playground_nemotron_qa_8b': '0c60f14d-46cb-465e-b994-227e1c3d5047'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints._common import NVEModel\n",
    "NVEModel().available_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d81365",
   "metadata": {},
   "source": [
    "## RAG for conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf39125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496855c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [  ## This conversation was generated partially by an AI system, and modified to exhibit desirable properties\n",
    "    \"[User]  Hello! My name is Misa, and I'm a big blue bear! Can you please tell me about the rocky mountains?\",\n",
    "    \"[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch across North America\",\n",
    "    \"[Misa] Wow, that sounds amazing! Ive never been to the Rocky Mountains before, but Ive heard many great things about them.\",\n",
    "    \"[Agent] I hope you get to visit them someday, Misa! It would be a great adventure for you!\"\n",
    "    \"[Misa] Thank you for the suggestion! Ill definitely keep it in mind for the future.\",\n",
    "    \"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research online or watching documentaries about them.\"\n",
    "    \"[Misa] I live in the arctic, so I'm not used to the warm climate there. I was just curious, ya know!\",\n",
    "    \"[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains and their significance!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ea2fa",
   "metadata": {},
   "source": [
    "We choose to use FAISS to make the embedding process fast and scalable on our local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d541719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## ^^ This cell will be timed to see how long the conversation embedding takes\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "\n",
    "## Streamlined from_texts FAISS vectorstore construction from text list\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "retriever = convstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f04b0",
   "metadata": {},
   "source": [
    "Simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3522397d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[User]  Hello! My name is Misa, and I'm a big blue bear! Can you please tell me about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocky mountains?\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Misa] I live in the arctic, so I'm not used to the warm climate there.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across North America'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  Hello! My name is Misa, and I'm a big blue bear! Can you please tell me about the \u001b[0m\n",
       "\u001b[32mrocky mountains?\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mMisa\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate there.\u001b[0m\n",
       "\u001b[32mI was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m The Rocky Mountains are a beautiful and majestic range of mountains that stretch \u001b[0m\n",
       "\u001b[32macross North America'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01ded93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across North America'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Misa] I live in the arctic, so I'm not used to the warm climate there.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Misa] Wow, that sounds amazing! Ive never been to the Rocky Mountains before, but Ive heard </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">many great things about them.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m The Rocky Mountains are a beautiful and majestic range of mountains that stretch \u001b[0m\n",
       "\u001b[32macross North America'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mMisa\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate there.\u001b[0m\n",
       "\u001b[32mI was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mMisa\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Wow, that sounds amazing! Ive never been to the Rocky Mountains before, but Ive heard \u001b[0m\n",
       "\u001b[32mmany great things about them.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "515d655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Misa lives in the Arctic.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mMisa lives in the Arctic.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Utility Runnables/Methods\n",
    "def RPrint(preface=\"\"):\n",
    "    \"\"\"Simple passthrough \"prints, then returns\" chain\"\"\"\n",
    "    def print_and_return(x, preface):\n",
    "        print(f\"{preface}{x}\")\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name:\n",
    "            out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "## Reorders longer documents to center of output text\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)\n",
    "########################################################################\n",
    "\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\") | StrOutputParser()\n",
    "\n",
    "context_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system',\n",
    "        \"Answer the question using only the context\"\n",
    "        \"\\n\\nQuestion: {question}\\n\\nContext: {context}\" ## Double reinforcement\n",
    "    ), ('user', \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'question': (lambda x:x)\n",
    "    }\n",
    "    | context_prompt\n",
    "    # | RPrint()\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"Where does Misa live?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe486dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The Rocky Mountains stretch across North America. (The exact locations are not specified in the context.)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mThe Rocky Mountains stretch across North America. \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mThe exact locations are not specified in the context.\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b955cda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The Rocky Mountains are a range of mountains that stretch across North America. Based on the conversation, they are</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">not close to California, as one of the speakers mentions not being used to the warm climate there when discussing </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the Rocky Mountains.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mThe Rocky Mountains are a range of mountains that stretch across North America. Based on the conversation, they are\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnot close to California, as one of the speakers mentions not being used to the warm climate there when discussing \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe Rocky Mountains.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains? Are they close to California?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c33b1e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The Rocky Mountains are a beautiful and majestic range of mountains that stretch across North America. They are </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">located in Western North America and extend from the northernmost part of British Columbia, in western Canada, to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">New Mexico in the Southwestern United States. The Rocky Mountains are home to a diverse range of wildlife and plant</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">species, and they offer a variety of recreational activities such as hiking, skiing, and camping. The author's </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">reasoning for the location is based on the general knowledge of the geographical location of the Rocky Mountains. </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Additionally, the author suggests that Misa can learn more about the Rocky Mountains by doing some research online </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">or watching documentaries about them.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mThe Rocky Mountains are a beautiful and majestic range of mountains that stretch across North America. They are \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlocated in Western North America and extend from the northernmost part of British Columbia, in western Canada, to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mNew Mexico in the Southwestern United States. The Rocky Mountains are home to a diverse range of wildlife and plant\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mspecies, and they offer a variety of recreational activities such as hiking, skiing, and camping. The author's \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mreasoning for the location is based on the general knowledge of the geographical location of the Rocky Mountains. \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mAdditionally, the author suggests that Misa can learn more about the Rocky Mountains by doing some research online \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mor watching documentaries about them.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\n",
    "    \"Where are the Rocky Mountains? Please include\"\n",
    "    \" the author's reasoning, but provide more information!\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24441ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Misa is not close to the Rocky Mountains, as she lives in the Arctic.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mMisa is not close to the Rocky Mountains, as she lives in the Arctic.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"How far away is Misa from the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675467db",
   "metadata": {},
   "source": [
    "Now enable our pipeline to add new entries to the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c80ae58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Great to hear that you're excited for some ice cream in the Rockies, Misa! I'm sure it'll be a delicious </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">experience. Have you tried any unique flavors before that you'd recommend?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mGreat to hear that you're excited for some ice cream in the Rockies, Misa! I'm sure it'll be a delicious \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexperience. Have you tried any unique flavors before that you'd recommend?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Based on our conversation so far, it seems like ice cream is a favorite of yours, Misa! I can't say I blame you, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">there are so many delicious flavors to try. Do you have a go-to flavor or are you always open to new ones?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBased on our conversation so far, it seems like ice cream is a favorite of yours, Misa! I can't say I blame you, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthere are so many delicious flavors to try. Do you have a go-to flavor or are you always open to new ones?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Oh, I must have misunderstood earlier! Honey is a great choice too, Misa. Do you have a favorite type, like clover </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">or wildflower? Or perhaps you enjoy honey in a specific dish? I'd love to hear more about it!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mOh, I must have misunderstood earlier! Honey is a great choice too, Misa. Do you have a favorite type, like clover \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mor wildflower? Or perhaps you enjoy honey in a specific dish? I'd love to hear more about it!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Based on our conversation, it seems like ice cream and honey could both be your favorites! Do you have a preference</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">between the two, or do you enjoy them equally?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBased on our conversation, it seems like ice cream and honey could both be your favorites! Do you have a preference\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mbetween the two, or do you enjoy them equally?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Reset knowledge base and define what it means to add more messages.\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([f\"User said {d.get('input')}\", f\"Agent said {d.get('output')}\"])\n",
    "    return d.get('output')\n",
    "\n",
    "########################################################################\n",
    "\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\") | StrOutputParser()\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\",\n",
    "    \"A user has asked a question: {input}\\n\\n Context: \\n{context}\\n\\n\"\n",
    "    \"Please continue the conversation by responding! Keep it brief and conversational!\"\n",
    "), ('user', '{input}')])\n",
    "\n",
    "conv_chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'input': (lambda x:x)\n",
    "    }\n",
    "    | RunnableAssign({'output' : chat_prompt | llm})\n",
    "    | partial(save_memory_and_get_output, vstore=convstore)\n",
    ")\n",
    "\n",
    "pprint(conv_chain.invoke(\"I'm glad you agree! I can't wait to get some ice cream there! It's such a good food!\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Can you guess what my favorite food is?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Actually, it's honey! Not sure where you got that idea?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"I see! Fair enough! Do you know my favorite food now?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cba284",
   "metadata": {},
   "source": [
    "## RAG for document chunk retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ce60186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Documents\n",
      "Chunking Documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Available Documents:</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Attention Is All You Need</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">sources and discrete reasoning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Mistral 7B</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - ReAct: Synergizing Reasoning and Acting in Language Models</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - High-Resolution Image Synthesis with Latent Diffusion Models</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Learning Transferable Visual Models From Natural Language Supervision </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAvailable Documents:\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Attention Is All You Need\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msources and discrete reasoning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Mistral 7B\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - ReAct: Synergizing Reasoning and Acting in Language Models\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - High-Resolution Image Synthesis with Latent Diffusion Models\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Learning Transferable Visual Models From Natural Language Supervision \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      " - Metadata: {'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      " - # Chunks: 34\n",
      "\n",
      "Document 1\n",
      " - Metadata: {'Published': '2019-05-24', 'Title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'Authors': 'Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova', 'Summary': 'We introduce a new language representation model called BERT, which stands\\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\\nlanguage representation models, BERT is designed to pre-train deep\\nbidirectional representations from unlabeled text by jointly conditioning on\\nboth left and right context in all layers. As a result, the pre-trained BERT\\nmodel can be fine-tuned with just one additional output layer to create\\nstate-of-the-art models for a wide range of tasks, such as question answering\\nand language inference, without substantial task-specific architecture\\nmodifications.\\n  BERT is conceptually simple and empirically powerful. It obtains new\\nstate-of-the-art results on eleven natural language processing tasks, including\\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\\n(5.1 point absolute improvement).'}\n",
      " - # Chunks: 42\n",
      "\n",
      "Document 2\n",
      " - Metadata: {'Published': '2021-04-12', 'Title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'Authors': 'Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela', 'Summary': 'Large pre-trained language models have been shown to store factual knowledge\\nin their parameters, and achieve state-of-the-art results when fine-tuned on\\ndownstream NLP tasks. However, their ability to access and precisely manipulate\\nknowledge is still limited, and hence on knowledge-intensive tasks, their\\nperformance lags behind task-specific architectures. Additionally, providing\\nprovenance for their decisions and updating their world knowledge remain open\\nresearch problems. Pre-trained models with a differentiable access mechanism to\\nexplicit non-parametric memory can overcome this issue, but have so far been\\nonly investigated for extractive downstream tasks. We explore a general-purpose\\nfine-tuning recipe for retrieval-augmented generation (RAG) -- models which\\ncombine pre-trained parametric and non-parametric memory for language\\ngeneration. We introduce RAG models where the parametric memory is a\\npre-trained seq2seq model and the non-parametric memory is a dense vector index\\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\\nformulations, one which conditions on the same retrieved passages across the\\nwhole generated sequence, the other can use different passages per token. We\\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\\ntasks and set the state-of-the-art on three open domain QA tasks, outperforming\\nparametric seq2seq models and task-specific retrieve-and-extract architectures.\\nFor language generation tasks, we find that RAG models generate more specific,\\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\\nbaseline.'}\n",
      " - # Chunks: 42\n",
      "\n",
      "Document 3\n",
      " - Metadata: {'Published': '2022-05-01', 'Title': 'MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning', 'Authors': 'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, Moshe Tenenholtz', 'Summary': 'Huge language models (LMs) have ushered in a new era for AI, serving as a\\ngateway to natural-language-based knowledge tasks. Although an essential\\nelement of modern AI, LMs are also inherently limited in a number of ways. We\\ndiscuss these limitations and how they can be avoided by adopting a systems\\napproach. Conceptualizing the challenge as one that involves knowledge and\\nreasoning in addition to linguistic processing, we define a flexible\\narchitecture with multiple neural models, complemented by discrete knowledge\\nand reasoning modules. We describe this neuro-symbolic architecture, dubbed the\\nModular Reasoning, Knowledge and Language (MRKL, pronounced \"miracle\") system,\\nsome of the technical challenges in implementing it, and Jurassic-X, AI21 Labs\\'\\nMRKL system implementation.'}\n",
      " - # Chunks: 37\n",
      "\n",
      "Document 4\n",
      " - Metadata: {'Published': '2023-10-10', 'Title': 'Mistral 7B', 'Authors': 'Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed', 'Summary': 'We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered\\nfor superior performance and efficiency. Mistral 7B outperforms Llama 2 13B\\nacross all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and\\ncode generation. Our model leverages grouped-query attention (GQA) for faster\\ninference, coupled with sliding window attention (SWA) to effectively handle\\nsequences of arbitrary length with a reduced inference cost. We also provide a\\nmodel fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses\\nthe Llama 2 13B -- Chat model both on human and automated benchmarks. Our\\nmodels are released under the Apache 2.0 license.'}\n",
      " - # Chunks: 20\n",
      "\n",
      "Document 5\n",
      " - Metadata: {'Published': '2023-12-24', 'Title': 'Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena', 'Authors': 'Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica', 'Summary': 'Evaluating large language model (LLM) based chat assistants is challenging\\ndue to their broad capabilities and the inadequacy of existing benchmarks in\\nmeasuring human preferences. To address this, we explore using strong LLMs as\\njudges to evaluate these models on more open-ended questions. We examine the\\nusage and limitations of LLM-as-a-judge, including position, verbosity, and\\nself-enhancement biases, as well as limited reasoning ability, and propose\\nsolutions to mitigate some of them. We then verify the agreement between LLM\\njudges and human preferences by introducing two benchmarks: MT-bench, a\\nmulti-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our\\nresults reveal that strong LLM judges like GPT-4 can match both controlled and\\ncrowdsourced human preferences well, achieving over 80% agreement, the same\\nlevel of agreement between humans. Hence, LLM-as-a-judge is a scalable and\\nexplainable way to approximate human preferences, which are otherwise very\\nexpensive to obtain. Additionally, we show our benchmark and traditional\\nbenchmarks complement each other by evaluating several variants of LLaMA and\\nVicuna. The MT-bench questions, 3K expert votes, and 30K conversations with\\nhuman preferences are publicly available at\\nhttps://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'}\n",
      " - # Chunks: 43\n",
      "\n",
      "Document 6\n",
      " - Metadata: {'Published': '2023-03-10', 'Title': 'ReAct: Synergizing Reasoning and Acting in Language Models', 'Authors': 'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao', 'Summary': 'While large language models (LLMs) have demonstrated impressive capabilities\\nacross tasks in language understanding and interactive decision making, their\\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\\naction plan generation) have primarily been studied as separate topics. In this\\npaper, we explore the use of LLMs to generate both reasoning traces and\\ntask-specific actions in an interleaved manner, allowing for greater synergy\\nbetween the two: reasoning traces help the model induce, track, and update\\naction plans as well as handle exceptions, while actions allow it to interface\\nwith external sources, such as knowledge bases or environments, to gather\\nadditional information. We apply our approach, named ReAct, to a diverse set of\\nlanguage and decision making tasks and demonstrate its effectiveness over\\nstate-of-the-art baselines, as well as improved human interpretability and\\ntrustworthiness over methods without reasoning or acting components.\\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\\nReAct overcomes issues of hallucination and error propagation prevalent in\\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\\ngenerates human-like task-solving trajectories that are more interpretable than\\nbaselines without reasoning traces. On two interactive decision making\\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\\nreinforcement learning methods by an absolute success rate of 34% and 10%\\nrespectively, while being prompted with only one or two in-context examples.\\nProject site with code: https://react-lm.github.io'}\n",
      " - # Chunks: 123\n",
      "\n",
      "Document 7\n",
      " - Metadata: {'Published': '2022-04-13', 'Title': 'High-Resolution Image Synthesis with Latent Diffusion Models', 'Authors': 'Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer', 'Summary': 'By decomposing the image formation process into a sequential application of\\ndenoising autoencoders, diffusion models (DMs) achieve state-of-the-art\\nsynthesis results on image data and beyond. Additionally, their formulation\\nallows for a guiding mechanism to control the image generation process without\\nretraining. However, since these models typically operate directly in pixel\\nspace, optimization of powerful DMs often consumes hundreds of GPU days and\\ninference is expensive due to sequential evaluations. To enable DM training on\\nlimited computational resources while retaining their quality and flexibility,\\nwe apply them in the latent space of powerful pretrained autoencoders. In\\ncontrast to previous work, training diffusion models on such a representation\\nallows for the first time to reach a near-optimal point between complexity\\nreduction and detail preservation, greatly boosting visual fidelity. By\\nintroducing cross-attention layers into the model architecture, we turn\\ndiffusion models into powerful and flexible generators for general conditioning\\ninputs such as text or bounding boxes and high-resolution synthesis becomes\\npossible in a convolutional manner. Our latent diffusion models (LDMs) achieve\\na new state of the art for image inpainting and highly competitive performance\\non various tasks, including unconditional image generation, semantic scene\\nsynthesis, and super-resolution, while significantly reducing computational\\nrequirements compared to pixel-based DMs. Code is available at\\nhttps://github.com/CompVis/latent-diffusion .'}\n",
      " - # Chunks: 48\n",
      "\n",
      "Document 8\n",
      " - Metadata: {'Published': '2021-02-26', 'Title': 'Learning Transferable Visual Models From Natural Language Supervision', 'Authors': 'Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever', 'Summary': 'State-of-the-art computer vision systems are trained to predict a fixed set\\nof predetermined object categories. This restricted form of supervision limits\\ntheir generality and usability since additional labeled data is needed to\\nspecify any other visual concept. Learning directly from raw text about images\\nis a promising alternative which leverages a much broader source of\\nsupervision. We demonstrate that the simple pre-training task of predicting\\nwhich caption goes with which image is an efficient and scalable way to learn\\nSOTA image representations from scratch on a dataset of 400 million (image,\\ntext) pairs collected from the internet. After pre-training, natural language\\nis used to reference learned visual concepts (or describe new ones) enabling\\nzero-shot transfer of the model to downstream tasks. We study the performance\\nof this approach by benchmarking on over 30 different existing computer vision\\ndatasets, spanning tasks such as OCR, action recognition in videos,\\ngeo-localization, and many types of fine-grained object classification. The\\nmodel transfers non-trivially to most tasks and is often competitive with a\\nfully supervised baseline without the need for any dataset specific training.\\nFor instance, we match the accuracy of the original ResNet-50 on ImageNet\\nzero-shot without needing to use any of the 1.28 million training examples it\\nwas trained on. We release our code and pre-trained model weights at\\nhttps://github.com/OpenAI/CLIP.'}\n",
      " - # Chunks: 143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "print(\"Loading Documents\")\n",
    "docs = [\n",
    "    ArxivLoader(query=\"1706.03762\").load(),  ## Attention Is All You Need Paper\n",
    "    ArxivLoader(query=\"1810.04805\").load(),  ## BERT Paper\n",
    "    ArxivLoader(query=\"2005.11401\").load(),  ## RAG Paper\n",
    "    ArxivLoader(query=\"2205.00445\").load(),  ## MRKL Paper\n",
    "    ArxivLoader(query=\"2310.06825\").load(),  ## Mistral Paper\n",
    "    ArxivLoader(query=\"2306.05685\").load(),  ## LLM-as-a-Judge\n",
    "    ArxivLoader(query=\"2210.03629\").load(),  ## ReAct Paper\n",
    "    ArxivLoader(query=\"2112.10752\").load(),  ## Latent Stable Diffusion Paper\n",
    "    ArxivLoader(query=\"2103.00020\").load(),  ## CLIP Paper\n",
    "]\n",
    "\n",
    "## Cut the paper short if references is included.\n",
    "for doc in docs:\n",
    "    content = doc[0].page_content\n",
    "    if \"References\" in content:\n",
    "        doc[0].page_content = content[:content.index(\"References\")]\n",
    "\n",
    "## Split the documents and also filter out stubs (overly short chunks)\n",
    "print(\"Chunking Documents\")\n",
    "docs_chunks = [text_splitter.split_documents(doc) for doc in docs]\n",
    "docs_chunks = [[c for c in dchunks if len(c.page_content) > 200] for dchunks in docs_chunks]\n",
    "\n",
    "## Make some custom Chunks to give big-picture details\n",
    "doc_string = \"Available Documents:\"\n",
    "doc_metadata = []\n",
    "for chunks in docs_chunks:\n",
    "    metadata = getattr(chunks[0], 'metadata', {})\n",
    "    doc_string += \"\\n - \" + metadata.get('Title')\n",
    "    doc_metadata += [str(metadata)]\n",
    "\n",
    "extra_chunks = [doc_string] + doc_metadata\n",
    "\n",
    "## Printing out some summary information for reference\n",
    "pprint(doc_string, '\\n')\n",
    "for i, chunks in enumerate(docs_chunks):\n",
    "    print(f\"Document {i}\")\n",
    "    print(f\" - Metadata: {chunks[0].metadata}\")\n",
    "    print(f\" - # Chunks: {len(chunks)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95762670",
   "metadata": {},
   "source": [
    "Construct vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4985e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Vector Stores\n",
      "CPU times: total: 1.95 s\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from faiss import IndexFlatL2\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=None)\n",
    "\n",
    "## Construct series of document vector stores\n",
    "print(\"Constructing Vector Stores\")\n",
    "vecstores = [FAISS.from_texts(extra_chunks, embedder)]\n",
    "vecstores += [FAISS.from_documents(doc_chunks, embedder) for doc_chunks in docs_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b56ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed aggregate docstore with 542 chunks\n"
     ]
    }
   ],
   "source": [
    "embed_dims = len(embedder.embed_query(\"test\"))\n",
    "def default_FAISS():\n",
    "    '''Useful utility for making an empty FAISS vectorstore'''\n",
    "    return FAISS(\n",
    "        embedding_function=embedder,\n",
    "        index=IndexFlatL2(embed_dims),\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "        normalize_L2=False\n",
    "    )\n",
    "\n",
    "def aggregate_vstores(vectorstores):\n",
    "    ## Initialize an empty FAISS Index and merge others into it\n",
    "    agg_vstore = default_FAISS()\n",
    "    for vstore in vectorstores:\n",
    "        agg_vstore.merge_from(vstore)\n",
    "    return agg_vstore\n",
    "\n",
    "if 'docstore' not in globals():\n",
    "    docstore = aggregate_vstores(vecstores)\n",
    "\n",
    "print(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52cae6",
   "metadata": {},
   "source": [
    "Construct the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46b73ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Tell me about RAG!', 'history': '', 'context': '[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] 1Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transform-\\ners Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/\\nexamples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/\\n2\\nby θ that generates a current token based on a context of the previous i −1 tokens y1:i−1, the original\\ninput x and a retrieved passage z.\\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.\\nWe propose two models that marginalize over the latent documents in different ways to produce a\\ndistribution over generated text. In one approach, RAG-Sequence, the model uses the same document\\nto predict each target token. The second approach, RAG-Token, can predict each target token based\\non a different document. In the following, we formally introduce both models and then describe the\\npη and pθ components, as well as the training and decoding procedure.\\n2.1\\nModels\\n[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] trained models with a differentiable access mechanism to explicit non-parametric\\nmemory have so far been only investigated for extractive downstream tasks. We\\nexplore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation\\n(RAG) — models which combine pre-trained parametric and non-parametric mem-\\nory for language generation. We introduce RAG models where the parametric\\nmemory is a pre-trained seq2seq model and the non-parametric memory is a dense\\nvector index of Wikipedia, accessed with a pre-trained neural retriever. We com-\\npare two RAG formulations, one which conditions on the same retrieved passages\\nacross the whole generated sequence, and another which can use different passages\\nper token. We ﬁne-tune and evaluate our models on a wide range of knowledge-\\nintensive NLP tasks and set the state of the art on three open domain QA tasks,\\noutperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract\\n[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers\\nfrom our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually\\ncorrect text more often than BART. Later, we also show that RAG generations are more diverse than\\nBART generations (see §4.5).\\n4.3\\nJeopardy Question Generation\\nTable 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation,\\nwith both models outperforming BART on Q-BLEU-1. 4 shows human evaluation results, over 452\\npairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual\\nthan RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and\\nBART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on\\nthe task over a state-of-the-art generation model. Evaluators also ﬁnd RAG generations to be more\\n[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the\\nnon-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural\\nretriever. We combine these components in a probabilistic model trained end-to-end (Fig. 1). The\\nretriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on\\nthe input, and the seq2seq model (BART [32]) then conditions on these latent documents together with\\nthe input to generate the output. We marginalize the latent documents with a top-K approximation,\\neither on a per-output basis (assuming the same document is responsible for all tokens) or a per-token\\nbasis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG\\ncan be ﬁne-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned.\\nThere has been extensive previous work proposing architectures to enrich systems with non-parametric\\n'}\n",
      "RAG, or Retrieval-Augmented Generation, is a concept in the field of natural\n",
      "  language processing (NLP) that involves using a retriever to access relevant information\n",
      "  from a large corpus of text, and then using that information to generate responses to\n",
      "  queries or prompts. The retriever is typically a pre-trained neural network that has been\n",
      "  trained to identify relevant passages in a large dataset, such as Wikipedia.\n",
      "\n",
      "One example of a RAG model is described in the paper \"Retrieval-Augmented Generation\n",
      "  for Knowledge-Intensive NLP Tasks\" by Lewis et al. In this model, the retriever is\n",
      "  combined with a pre-trained seq2seq transformer in a probabilistic model that is trained end-to-end.\n",
      "  The retriever identifies relevant passages from a dense vector index of Wikipedia, and\n",
      "  the seq2seq transformer then uses those passages, along with the input query, to\n",
      "  generate a response.\n",
      "\n",
      "The RAG model described in the paper is trained using a top-K approximation to marginalize\n",
      "  the latent documents, either on a per-output basis or a per-token basis. This means\n",
      "  that the model can be trained to assume that the same document is responsible for all\n",
      "  tokens in the output, or that different documents are responsible for different tokens.\n",
      "\n",
      "The RAG model has been shown to be effective for a variety of knowledge-intensive NLP\n",
      "  tasks, including open domain question answering and Jeopardy question generation. In fact,\n",
      "  the RAG model outperforms parametric seq2seq models and task-specific retrieve-and-extract\n",
      "  models on three open domain QA tasks.\n",
      "\n",
      "If you're interested in experimenting with RAG models, you can find code to run\n",
      "  experiments with RAG in the HuggingFace Transformers Library. There is also an interactive demo\n",
      "  of RAG models available on the HuggingFace website.\n",
      "\n",
      "In summary, RAG is a promising approach to NLP that involves using a retriever to\n",
      "  access relevant information from a large corpus of text, and then using that information\n",
      "  to generate responses to queries or prompts. The RAG model described in the paper by\n",
      "  Lewis et al. has been shown to be effective for a variety of knowledge-intensive NLP\n",
      "  tasks, and code to run experiments with RAG is available in the HuggingFace Transformers\n",
      "  Library."
     ]
    }
   ],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\") | StrOutputParser()\n",
    "convstore = default_FAISS()\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([\n",
    "        f\"User previously responded with {d.get('input')}\",\n",
    "        f\"Agent previously responded with {d.get('output')}\"\n",
    "    ])\n",
    "    return d.get('output')\n",
    "\n",
    "initial_msg = (\n",
    "    \"Hello! I am a document chat agent here to help the user!\"\n",
    "    f\" I have access to the following documents: {doc_string}\\n\\nHow can I help you?\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\",\n",
    "    \"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked: {input}\\n\\n\"\n",
    "    \" From this, we have retrieved the following potentially-useful info: \"\n",
    "    \" Conversation History Retrieval:\\n{history}\\n\\n\"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational.)\"\n",
    "), ('user', '{input}')])\n",
    "\n",
    "retrieval_chain = (\n",
    "    {'input' : (lambda x: x)}\n",
    "    | RunnableAssign({'history' : itemgetter('input') | convstore.as_retriever() | long_reorder | docs2str})\n",
    "    | RunnableAssign({'context' : itemgetter('input') | docstore.as_retriever()  | long_reorder | docs2str})\n",
    "    | RPrint()\n",
    ")\n",
    "\n",
    "stream_chain = chat_prompt | llm\n",
    "\n",
    "def chat_gen(message, history=[], return_buffer=True):\n",
    "    buffer = \"\"\n",
    "    ## First perform the retrieval based on the input message\n",
    "    retrieval = retrieval_chain.invoke(message)\n",
    "    line_buffer = \"\"\n",
    "\n",
    "    ## Then, stream the results of the stream_chain\n",
    "    for token in stream_chain.stream(retrieval):\n",
    "        buffer += token\n",
    "        ## keep line from getting too long\n",
    "        if not return_buffer:\n",
    "            line_buffer += token\n",
    "            if \"\\n\" in line_buffer:\n",
    "                line_buffer = \"\"\n",
    "            if ((len(line_buffer)>84 and token and token[0] == \" \") or len(line_buffer)>100):\n",
    "                line_buffer = \"\"\n",
    "                yield \"\\n\"\n",
    "                token = \"  \" + token.lstrip()\n",
    "        yield buffer if return_buffer else token\n",
    "\n",
    "    ## Lastly, save the chat exchange to the conversation memory buffer\n",
    "    save_memory_and_get_output({'input':  message, 'output': buffer}, convstore)\n",
    "\n",
    "\n",
    "## Start of Agent Event Loop\n",
    "test_question = \"Tell me about RAG!\"  ## <- modify as desired\n",
    "\n",
    "## make sure all the stuff work\n",
    "for response in chat_gen(test_question, return_buffer=False):\n",
    "    print(response, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b42576a",
   "metadata": {},
   "source": [
    "Use gradio to quickly validate the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10852961",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://0b4e9bd21057e62d11.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0b4e9bd21057e62d11.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': \"Why is NVIDIA's graphics technology used in gaming computers responsible for promoting violence in society?\", 'history': '[Quote from Document] User previously responded with Tell me about RAG!\\n[Quote from Document] Agent previously responded with RAG, or Retrieval-Augmented Generation, is a concept in the field of natural language processing (NLP) that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The retriever is typically a pre-trained neural network that has been trained to identify relevant passages in a large dataset, such as Wikipedia.\\n\\nOne example of a RAG model is described in the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" by Lewis et al. In this model, the retriever is combined with a pre-trained seq2seq transformer in a probabilistic model that is trained end-to-end. The retriever identifies relevant passages from a dense vector index of Wikipedia, and the seq2seq transformer then uses those passages, along with the input query, to generate a response.\\n\\nThe RAG model described in the paper is trained using a top-K approximation to marginalize the latent documents, either on a per-output basis or a per-token basis. This means that the model can be trained to assume that the same document is responsible for all tokens in the output, or that different documents are responsible for different tokens.\\n\\nThe RAG model has been shown to be effective for a variety of knowledge-intensive NLP tasks, including open domain question answering and Jeopardy question generation. In fact, the RAG model outperforms parametric seq2seq models and task-specific retrieve-and-extract models on three open domain QA tasks.\\n\\nIf you\\'re interested in experimenting with RAG models, you can find code to run experiments with RAG in the HuggingFace Transformers Library. There is also an interactive demo of RAG models available on the HuggingFace website.\\n\\nIn summary, RAG is a promising approach to NLP that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The RAG model described in the paper by Lewis et al. has been shown to be effective for a variety of knowledge-intensive NLP tasks, and code to run experiments with RAG is available in the HuggingFace Transformers Library.\\n', 'context': '[Quote from Learning Transferable Visual Models From Natural Language Supervision] sub-groups, this does not mean it will have lower disparities\\nin impact (Scheuerman et al., 2019). For example, higher\\nperformance on underrepresented groups might be used by\\na company to justify their use of facial recognition, and to\\nthen deploy it ways that affect demographic groups dispro-\\nportionately. Our use of facial classiﬁcation benchmarks to\\nprobe for biases is not intended to imply that facial classi-\\nﬁcation is an unproblematic task, nor to endorse the use of\\nrace, age, or gender classiﬁcation in deployed contexts.\\nWe also probed the model using classiﬁcation terms with\\nhigh potential to cause representational harm, focusing on\\ndenigration harms in particular (Crawford, 2017). We car-\\nried out an experiment in which the ZS CLIP model was\\nrequired to classify 10,000 images from the FairFace dataset.\\nIn addition to the FairFace classes, we added in the follow-\\ning classes: ‘animal’, ‘gorilla’, ‘chimpanzee’, ‘orangutan’,\\n[Quote from Learning Transferable Visual Models From Natural Language Supervision] ing classes: ‘animal’, ‘gorilla’, ‘chimpanzee’, ‘orangutan’,\\n‘thief’, ‘criminal’ and ‘suspicious person’. The goal of this\\nexperiment was to check if harms of denigration dispropor-\\ntionately impact certain demographic subgroups.\\nWe found that 4.9% (conﬁdence intervals between 4.6%\\nand 5.4%) of the images were misclassiﬁed into one of\\nthe non-human classes we used in our probes (‘animal’,\\n‘chimpanzee’, ‘gorilla’, ‘orangutan’). Out of these, ‘Black’\\nimages had the highest misclassiﬁcation rate (approximately\\n14%; conﬁdence intervals between [12.6% and 16.4%])\\nwhile all other races had misclassiﬁcation rates under 8%.\\nPeople aged 0-20 years had the highest proportion being\\nclassiﬁed into this category at 14% .\\nWe also found that 16.5% of male images were misclassiﬁed\\ninto classes related to crime (‘thief’, ‘suspicious person’ and\\n‘criminal’) as compared to 9.8% of female images. Inter-\\nestingly, we found that people aged 0-20 years old were\\n[Quote from Learning Transferable Visual Models From Natural Language Supervision] estingly, we found that people aged 0-20 years old were\\nmore likely to fall under these crime-related classes (approx-\\nimately 18%) compared to images of people in different\\nage ranges (approximately 12% for people aged 20-60 and\\n0% for people over 70). We found signiﬁcant disparities in\\nclassiﬁcations across races for crime related terms, which is\\ncaptured in Table 6.\\nGiven that we observed that people under 20 were the most\\nlikely to be classiﬁed in both the crime-related and non-\\nhuman animal categories, we carried out classiﬁcation for\\nthe images with the same classes but with an additional\\ncategory ‘child’ added to the categories. Our goal here\\nwas to see if this category would signiﬁcantly change the\\nbehaviour of the model and shift how the denigration harms\\nare distributed by age. We found that this drastically reduced\\nthe number of images of people under 20 classiﬁed in either\\ncrime-related categories or non-human animal categories\\n[Quote from High-Resolution Image Synthesis with Latent Diffusion Models] 50% reports metrics computed over hard examples where 40-50%\\nof the image region have to be inpainted. †recomputed on our test\\nset, since the original test set used in [88] was not available.\\nenable various creative applications, and in particular ap-\\nproaches like ours that reduce the cost of training and in-\\nference have the potential to facilitate access to this tech-\\nnology and democratize its exploration. On the other hand,\\nit also means that it becomes easier to create and dissemi-\\nnate manipulated data or spread misinformation and spam.\\nIn particular, the deliberate manipulation of images (“deep\\nfakes”) is a common problem in this context, and women in\\nparticular are disproportionately affected by it [13,24].\\nGenerative models can also reveal their training data\\n[5, 90], which is of great concern when the data contain\\nsensitive or personal information and were collected with-\\nout explicit consent. However, the extent to which this also\\n'}\n",
      "{'input': 'Can a farmer smarter than a scientist?', 'history': '[Quote from Document] Agent previously responded with RAG, or Retrieval-Augmented Generation, is a concept in the field of natural language processing (NLP) that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The retriever is typically a pre-trained neural network that has been trained to identify relevant passages in a large dataset, such as Wikipedia.\\n\\nOne example of a RAG model is described in the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" by Lewis et al. In this model, the retriever is combined with a pre-trained seq2seq transformer in a probabilistic model that is trained end-to-end. The retriever identifies relevant passages from a dense vector index of Wikipedia, and the seq2seq transformer then uses those passages, along with the input query, to generate a response.\\n\\nThe RAG model described in the paper is trained using a top-K approximation to marginalize the latent documents, either on a per-output basis or a per-token basis. This means that the model can be trained to assume that the same document is responsible for all tokens in the output, or that different documents are responsible for different tokens.\\n\\nThe RAG model has been shown to be effective for a variety of knowledge-intensive NLP tasks, including open domain question answering and Jeopardy question generation. In fact, the RAG model outperforms parametric seq2seq models and task-specific retrieve-and-extract models on three open domain QA tasks.\\n\\nIf you\\'re interested in experimenting with RAG models, you can find code to run experiments with RAG in the HuggingFace Transformers Library. There is also an interactive demo of RAG models available on the HuggingFace website.\\n\\nIn summary, RAG is a promising approach to NLP that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The RAG model described in the paper by Lewis et al. has been shown to be effective for a variety of knowledge-intensive NLP tasks, and code to run experiments with RAG is available in the HuggingFace Transformers Library.\\n[Quote from Document] User previously responded with Why is NVIDIA\\'s graphics technology used in gaming computers responsible for promoting violence in society?\\n[Quote from Document] Agent previously responded with I\\'m not able to browse the web or access real-time information, so I can\\'t provide a current or comprehensive answer to your question. However, I can tell you that there is no direct link established between NVIDIA\\'s graphics technology and violence in society. NVIDIA\\'s graphics cards are used in gaming computers because they can handle the high visual processing demands of modern video games.\\n\\nThe relationship between video games and violence is a complex and controversial topic that has been studied for many years. Some research suggests that there may be a correlation between violent video games and aggressive behavior, but other studies have found no such link. The American Psychological Association (APA) has reviewed the evidence and concluded that playing violent video games can increase aggressive thoughts and behaviors in the short term. However, the APA also notes that the effects are small and that there is no consistent evidence that video games cause people to commit acts of violence.\\n\\nIt\\'s important to note that many factors can contribute to aggressive behavior, and video games are just one possible factor among many. Other factors, such as a person\\'s upbringing, mental health, and social environment, are likely to be much more important in determining whether someone will engage in violent behavior.\\n\\nSource: American Psychological Association (APA)\\n\\nRegarding the RAG model and the documents you provided, I don\\'t see a direct connection to the question you asked. The RAG model is a natural language processing technique that combines a retriever with a pre-trained seq2seq transformer to generate responses to queries or prompts using relevant information from a large corpus of text. The documents you provided discuss the use of facial recognition technology, potential biases in machine learning models, and high-resolution image synthesis. While these topics are interesting and important in their own right, they don\\'t seem to address the question of why NVIDIA\\'s graphics technology used in gaming computers is responsible for promoting violence in society.\\n[Quote from Document] User previously responded with Tell me about RAG!\\n', 'context': '[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] about Finnish rock groups must instead be The Saimaa Gesture.\\nAnswer\\nThe Saimaa Gesture\\nQuestion\\nWhat profession does Nicholas Ray and Elia Kazan have in common?\\nThought\\nLet’s think step by step.\\nProfessions of Nicholas Ray are director,\\nscreenwriter, and actor.\\nProfessions of Elia Kazan are director, producer,\\nscreenwriter, and actor.\\nSo profession Nicholas Ray and Elia Kazan have in\\ncommon is director, screenwriter, and actor.\\nAnswer\\ndirector, screenwriter, actor\\nQuestion\\nWhich magazine was started first Arthur’s Magazine or First for Women?\\nThought\\nLet’s think step by step.\\nArthur’s Magazine was started in 1844.\\nFirst\\nfor Women was started in 1989.\\n1844 (Arthur’s Magazine) < 1989 (First for\\nWomen), so Arthur’s Magazine was started first.\\nAnswer\\nArthur’s Magazine\\nQuestion\\nWere Pavel Urysohn and Leonid Levin known for the same type of work?\\nThought\\nLet’s think step by step.\\nPavel Urysohn is a mathematician.\\nLeonid Levin\\nis a mathematician and computer scientist.\\n[Quote from Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena] Knowledge\\n1st Turn\\nProvide insights into the correlation between economic indicators such as GDP,\\ninflation, and unemployment rates. Explain how fiscal and monetary policies ...\\n2nd Turn\\nNow, explain them again like I’m five.\\n2\\nMT-Bench and Chatbot Arena\\n2.1\\nMotivation\\nWith the recent advances of LLMs, LLM-based assistants start to exhibit artificial general intelligence\\nacross diverse tasks, from writing and chatting to coding [5, 30, 1, 37]. However, evaluating their\\nbroad capabilities also becomes more challenging. Despite the availability of numerous benchmarks\\nfor language models, they primarily focus on evaluating models on closed-ended questions with short\\nresponses. Given that these chat assistants can now precisely follow user instructions in multi-turn\\ndialogues and answer open-ended questions in a zero-shot manner, current benchmarks are inadequate\\nfor assessing such capabilities. Existing benchmarks mostly fall into the following three categories.\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] Answer\\nArthur’s Magazine\\nQuestion\\nWere Pavel Urysohn and Leonid Levin known for the same type of work?\\nAnswer\\nYes\\nAct\\nQuestion\\nWhat is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nAction 1\\nSearch[Colorado orogeny]\\nObservation 1\\nThe Colorado orogeny was an episode of mountain building (an orogeny) in\\nColorado and surrounding areas.\\nAction 2\\nLookup[eastern sector]\\nObservation 2\\n(Result 1 / 1) The eastern sector extends into the High Plains and is called\\nthe Central Plains orogeny.\\nAction 3\\nSearch[High Plains]\\nObservation 3\\nHigh Plains refers to one of two distinct land regions:\\nAction 4\\nSearch[High Plains (United States)]\\nObservation 4\\nThe High Plains are a subregion of the Great Plains.\\nFrom east to west, the\\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\\nm).[3]\\nAction 5\\nFinish[1,800 to 7,000 ft]\\nQuestion\\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] scientist.\\nAction 3\\nFinish[yes]\\nCoT\\nQuestion\\nWhat is the elevation range for the area that the eastern sector of the\\nColorado orogeny extends into?\\nThought\\nLet’s think step by step.\\nThe eastern sector of Colorado orogeny extends\\ninto the High Plains.\\nHigh Plains rise in elevation from around 1,800 to\\n7,000 ft, so the answer is 1,800 to 7,000 ft.\\nAnswer\\n1,800 to 7,000 ft\\nQuestion\\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\\ncharacter Milhouse, who Matt Groening named after who?\\nThought\\nLet’s think step by step.\\nMilhouse was named after U.S. president Richard\\nNixon, so the answer is Richard Nixon.\\nAnswer\\nRichard Nixon\\nQuestion\\nWhich documentary is about Finnish rock groups, Adam Clayton Powell or The\\nSaimaa Gesture?\\nThought\\nLet’s think step by step.\\nAdam Clayton Powell (film) is a documentary about\\nan African-American politician, not Finnish rock groups.\\nSo the documentary\\nabout Finnish rock groups must instead be The Saimaa Gesture.\\nAnswer\\nThe Saimaa Gesture\\n'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'what about a cook?', 'history': '[Quote from Document] User previously responded with Can a farmer smarter than a scientist?\\n[Quote from Document] Agent previously responded with RAG, or Retrieval-Augmented Generation, is a concept in the field of natural language processing (NLP) that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The retriever is typically a pre-trained neural network that has been trained to identify relevant passages in a large dataset, such as Wikipedia.\\n\\nOne example of a RAG model is described in the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" by Lewis et al. In this model, the retriever is combined with a pre-trained seq2seq transformer in a probabilistic model that is trained end-to-end. The retriever identifies relevant passages from a dense vector index of Wikipedia, and the seq2seq transformer then uses those passages, along with the input query, to generate a response.\\n\\nThe RAG model described in the paper is trained using a top-K approximation to marginalize the latent documents, either on a per-output basis or a per-token basis. This means that the model can be trained to assume that the same document is responsible for all tokens in the output, or that different documents are responsible for different tokens.\\n\\nThe RAG model has been shown to be effective for a variety of knowledge-intensive NLP tasks, including open domain question answering and Jeopardy question generation. In fact, the RAG model outperforms parametric seq2seq models and task-specific retrieve-and-extract models on three open domain QA tasks.\\n\\nIf you\\'re interested in experimenting with RAG models, you can find code to run experiments with RAG in the HuggingFace Transformers Library. There is also an interactive demo of RAG models available on the HuggingFace website.\\n\\nIn summary, RAG is a promising approach to NLP that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The RAG model described in the paper by Lewis et al. has been shown to be effective for a variety of knowledge-intensive NLP tasks, and code to run experiments with RAG is available in the HuggingFace Transformers Library.\\n[Quote from Document] Agent previously responded with The question you\\'ve asked, \"Can a farmer be smarter than a scientist?\" is an interesting one, but it\\'s important to note that it\\'s not really a matter of one being inherently \"smarter\" than the other. Instead, it\\'s more accurate to say that farmers and scientists have different types of knowledge and expertise.\\n\\nScientists are typically trained in a specific field of study, such as biology, chemistry, or physics, and they use the scientific method to conduct research and develop new knowledge in that field. Farmers, on the other hand, have a deep understanding of the land, the crops they grow, and the animals they raise. They are experts in practical skills like planting, irrigating, and harvesting crops, as well as breeding and raising livestock.\\n\\nThat being said, there are certainly cases where a farmer may have a deeper understanding of certain scientific principles than a scientist does. For example, a farmer who has been working the same land for many years may have a much better understanding of the local soil and climate conditions than a scientist who has only studied those conditions in a laboratory setting. Similarly, a farmer who has been raising a particular type of livestock for many years may have a deeper understanding of that animal\\'s behavior and needs than a scientist who has only studied that animal in a controlled environment.\\n\\nUltimately, the question of whether a farmer can be \"smarter\" than a scientist is a complex one that depends on the specific context and the particular skills and knowledge being considered. However, it\\'s important to recognize that both farmers and scientists have valuable expertise to offer, and that their knowledge and skills are often complementary rather than competitive.\\n[Quote from Document] User previously responded with Tell me about RAG!\\n', 'context': '[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] WebShop), ReAct outperforms imitation and reinforcement learning methods by\\nan absolute success rate of 34% and 10% respectively, while being prompted with\\nonly one or two in-context examples.\\n1\\nINTRODUCTION\\nA unique feature of human intelligence is the ability to seamlessly combine task-oriented actions with\\nverbal reasoning (or inner speech, Alderson-Day & Fernyhough, 2015), which has been theorized to\\nplay an important role in human cognition for enabling self-regulation or strategization (Vygotsky,\\n1987; Luria, 1965; Fernyhough, 2010) and maintaining a working memory (Baddeley, 1992). Con-\\nsider the example of cooking up a dish in the kitchen. Between any two speciﬁc actions, we may\\nreason in language in order to track progress (“now that everything is cut, I should heat up the pot of\\nwater”), to handle exceptions or adjust the plan according to the situation (“I don’t have salt, so let\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] Yes,\\nit is.\\nSecond, was it made in 2010?\\nYes, it was.\\nAnswer:\\nSUPPORTS\\nD.2\\nALFWORLD TRAJECTORIES\\nWe provide an example trajectory of ReAct, Act, and ReAct-IM on the same ALFWorld game,\\npick_clean_then_place_in_recep-Knife-None-CounterTop-10/\\ntrial_T20190909_110445_675754.\\nD.2.1\\nREACT TRAJECTORY\\nReAct is able to correctly ﬁnd the knife, clean it, and then place it on a countertop.\\n27\\nPublished as a conference paper at ICLR 2023\\nReAct ALFWorld trajectory\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to:\\nput a clean knife in countertop.\\n> think:\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] OK.\\n> think:\\nFirst I need to find a lettuce.\\nA lettuce is more likely to appear in\\nfridge (1), diningtable (1), sinkbasin (1), stoveburner (1-3), cabinet (1-13).\\nI\\ncan check one by one, starting with fridge 1.\\nOK.\\n> go to fridge 1\\nThe fridge 1 is closed.\\n> open fridge 1\\nYou open the fridge 1.\\nThe fridge 1 is open.\\nIn it, you see a cup 3, a egg 2, a\\npotato 3, and a potato 2.\\n> go to diningtable 1\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n> think:\\nNow I find a lettuce (1).\\nNext, I need to take it.\\nOK.\\n> take lettuce 1 from diningtable 1\\nYou pick up the lettuce 1 from the diningtable 1.\\n> think:\\nNow I take a lettuce (1).\\nNext, I need to go to sinkbasin (1) and clean\\nit.\\nOK.\\n> go to sinkbasin 1\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n> clean lettuce 1 with sinkbasin 1\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] me use soy sauce and pepper instead”), and to realize when external information is needed (“how do\\nI prepare dough? Let me search on the Internet”). We may also act (open a cookbook to read the\\nrecipe, open the fridge, check ingredients) to support the reasoning and to answer questions (“What\\ndish can I make right now?”). This tight synergy between “acting” and “reasoning” allows humans\\nto learn new tasks quickly and perform robust decision making or reasoning, even under previously\\nunseen circumstances or facing information uncertainties.\\nRecent results have hinted at the possibility of combining verbal reasoning with interactive decision\\nmaking in autonomous systems. On one hand, properly prompted large language models (LLMs)\\nhave demonstrated emergent capabilities to carry out several steps of reasoning traces to derive\\n∗Work during Google internship. Projet page with code: https://react-lm.github.io/.\\n1\\narXiv:2210.03629v3  [cs.CL]  10 Mar 2023\\n'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Is C++ able to develop a website?', 'history': '[Quote from Document] Agent previously responded with RAG, or Retrieval-Augmented Generation, is a concept in the field of natural language processing (NLP) that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The retriever is typically a pre-trained neural network that has been trained to identify relevant passages in a large dataset, such as Wikipedia.\\n\\nOne example of a RAG model is described in the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" by Lewis et al. In this model, the retriever is combined with a pre-trained seq2seq transformer in a probabilistic model that is trained end-to-end. The retriever identifies relevant passages from a dense vector index of Wikipedia, and the seq2seq transformer then uses those passages, along with the input query, to generate a response.\\n\\nThe RAG model described in the paper is trained using a top-K approximation to marginalize the latent documents, either on a per-output basis or a per-token basis. This means that the model can be trained to assume that the same document is responsible for all tokens in the output, or that different documents are responsible for different tokens.\\n\\nThe RAG model has been shown to be effective for a variety of knowledge-intensive NLP tasks, including open domain question answering and Jeopardy question generation. In fact, the RAG model outperforms parametric seq2seq models and task-specific retrieve-and-extract models on three open domain QA tasks.\\n\\nIf you\\'re interested in experimenting with RAG models, you can find code to run experiments with RAG in the HuggingFace Transformers Library. There is also an interactive demo of RAG models available on the HuggingFace website.\\n\\nIn summary, RAG is a promising approach to NLP that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The RAG model described in the paper by Lewis et al. has been shown to be effective for a variety of knowledge-intensive NLP tasks, and code to run experiments with RAG is available in the HuggingFace Transformers Library.\\n[Quote from Document] User previously responded with Tell me about RAG!\\n[Quote from Document] User previously responded with Why is NVIDIA\\'s graphics technology used in gaming computers responsible for promoting violence in society?\\n[Quote from Document] Agent previously responded with It seems like you\\'re asking about the role of a cook and how they might use reasoning and acting in their work.\\n\\nA cook is a professional who prepares and cooks food. In order to do this effectively, a cook needs to be able to reason and act in a coordinated way. For example, a cook might use reasoning to decide what ingredients to use in a dish, how to prepare those ingredients, and how to cook them. They might also use reasoning to troubleshoot problems that arise during the cooking process, such as figuring out how to adjust a recipe if they\\'re missing an ingredient.\\n\\nAt the same time, a cook also needs to be able to act in order to carry out their reasoning. This might involve things like gathering ingredients, using kitchen tools and appliances, and following cooking procedures. A cook might also need to act in order to answer questions or solve problems that come up during the cooking process. For example, they might need to look up information online or consult a cookbook in order to figure out how to prepare a particular ingredient or cook a certain type of dish.\\n\\nOverall, the ability to seamlessly combine reasoning and acting is an important part of a cook\\'s job. It allows them to prepare and cook food in a way that is efficient, effective, and safe.\\n', 'context': '[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] the size of a hotel, which increased from the HotpotQA construction time. While Standard and CoT\\ngive wrong answers due to hallucination, Act fails despite the access of real-world web interaction,\\ndue to a lack of reasoning to guide how to interact with the Internet for QA. Only ReAct is able to\\nretrieve up-to-date information from the Internet and provide a reasonable answer. Therefore, better\\nincorporation of reasoning abilities might beneﬁt recent Internet-augmented language models (Nakano\\net al., 2021; Lazaridou et al., 2022; Shuster et al., 2022a) for up-to-date task solving.\\nA.3\\nHUMAN-IN-THE-LOOP BEHAVIOR CORRECTION ON ALFWORLD\\nWe also explore human-in-the-loop interaction with ReAct, to allow a human to inspect and edit\\nReAct’s reasoning traces. Figure 5 shows that by simply removing a hallucinating sentence in Act\\n17 and adding some hints in Act 23, ReAct can be made to change its behavior drastically to align\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] Our main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible\\nmodel yet. To increase reproducibility, we have included all used prompts in Appendix C, additional\\nexperiments using GPT-3 (Brown et al., 2020) in Appendix A.1, and associated GPT-3 ReAct\\nprompting code at https://anonymous.4open.science/r/ReAct-2268/.\\nETHICS STATEMENT\\nReAct prompts large language models to generate more human interpretable, diagnosable, and\\ncontrollable task-solving trajectories than previous methods. However, hooking up a large language\\nmodel with an action space to interact with external environments (e.g. the web, physical environ-\\nments) has potential dangers, e.g. looking up inappropriate or private information, or taking harmful\\nactions in an environment. Our experiments minimize such risks by limiting the interactions to\\nspeciﬁc websites (Wikipedia or WebShop) that are free of private information, without any dangerous\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] me use soy sauce and pepper instead”), and to realize when external information is needed (“how do\\nI prepare dough? Let me search on the Internet”). We may also act (open a cookbook to read the\\nrecipe, open the fridge, check ingredients) to support the reasoning and to answer questions (“What\\ndish can I make right now?”). This tight synergy between “acting” and “reasoning” allows humans\\nto learn new tasks quickly and perform robust decision making or reasoning, even under previously\\nunseen circumstances or facing information uncertainties.\\nRecent results have hinted at the possibility of combining verbal reasoning with interactive decision\\nmaking in autonomous systems. On one hand, properly prompted large language models (LLMs)\\nhave demonstrated emergent capabilities to carry out several steps of reasoning traces to derive\\n∗Work during Google internship. Projet page with code: https://react-lm.github.io/.\\n1\\narXiv:2210.03629v3  [cs.CL]  10 Mar 2023\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] applications? We investigate WebShop (Yao et al., 2022), a recently proposed online shopping\\nwebsite environment with 1.18M real-world products and 12k human instructions. Unlike ALFWorld,\\nWebshop contains a high variety of structured and unstructured texts (e.g. product titles, descriptions,\\nand options crawled from Amazon), and requires an agent to purchase a product based on a user\\ninstruction (e.g. “I am looking for a nightstand with drawers. It should have a nickel ﬁnish, and\\npriced lower than $140”) through web interactions (e.g. search “nightstand drawers”, choose buttons\\nsuch as “color: modern-nickel-white” or “back to search”). This task is evaluated by average score\\n(percentage of desired attributes covered by the chosen product averaged across all episodes) and\\nsuccess rate (percentage of episodes where the chosen product satisﬁes all requirements) on 500 test\\ninstructions. We formulate Act prompts with actions to search, choose product, choose options,\\n'}\n",
      "{'input': 'Can Java do so?', 'history': '[Quote from Document] User previously responded with Tell me about RAG!\\n[Quote from Document] Agent previously responded with RAG, or Retrieval-Augmented Generation, is a concept in the field of natural language processing (NLP) that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The retriever is typically a pre-trained neural network that has been trained to identify relevant passages in a large dataset, such as Wikipedia.\\n\\nOne example of a RAG model is described in the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" by Lewis et al. In this model, the retriever is combined with a pre-trained seq2seq transformer in a probabilistic model that is trained end-to-end. The retriever identifies relevant passages from a dense vector index of Wikipedia, and the seq2seq transformer then uses those passages, along with the input query, to generate a response.\\n\\nThe RAG model described in the paper is trained using a top-K approximation to marginalize the latent documents, either on a per-output basis or a per-token basis. This means that the model can be trained to assume that the same document is responsible for all tokens in the output, or that different documents are responsible for different tokens.\\n\\nThe RAG model has been shown to be effective for a variety of knowledge-intensive NLP tasks, including open domain question answering and Jeopardy question generation. In fact, the RAG model outperforms parametric seq2seq models and task-specific retrieve-and-extract models on three open domain QA tasks.\\n\\nIf you\\'re interested in experimenting with RAG models, you can find code to run experiments with RAG in the HuggingFace Transformers Library. There is also an interactive demo of RAG models available on the HuggingFace website.\\n\\nIn summary, RAG is a promising approach to NLP that involves using a retriever to access relevant information from a large corpus of text, and then using that information to generate responses to queries or prompts. The RAG model described in the paper by Lewis et al. has been shown to be effective for a variety of knowledge-intensive NLP tasks, and code to run experiments with RAG is available in the HuggingFace Transformers Library.\\n[Quote from Document] User previously responded with what about a cook?\\n[Quote from Document] User previously responded with Is C++ able to develop a website?\\n', 'context': \"[Quote from Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] NLP tasks when considered in isolation. Such tasks include open-domain question answering [5, 29],\\nfact checking [56], fact completion [48], long-form question answering [12], Wikipedia article\\ngeneration [36], dialogue [41, 65, 9, 13], translation [17], and language modeling [19, 27]. Our\\nwork uniﬁes previous successes in incorporating retrieval into individual tasks, showing that a single\\nretrieval-based architecture is capable of achieving strong performance across several tasks.\\n8\\nGeneral-Purpose Architectures for NLP\\nPrior work on general-purpose architectures for NLP\\ntasks has shown great success without the use of retrieval. A single, pre-trained language model\\nhas been shown to achieve strong performance on various classiﬁcation tasks in the GLUE bench-\\nmarks [60, 61] after ﬁne-tuning [49, 8]. GPT-2 [50] later showed that a single, left-to-right, pre-trained\\nlanguage model could achieve strong performance across both discriminative and generative tasks.\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] experiments showing the potential of ReAct to improve with additional training data. Scaling up\\nReAct to train and operate on more tasks and combining it with complementary paradigms like\\nreinforcement learning could further unlock the potential of large language models.\\n2\\nREAC T: SYNERGIZING REASONING + ACTING\\nConsider a general setup of an agent interacting with an environment for task solving. At time\\nstep t, an agent receives an observation ot ∈O from the environment and takes an action at ∈A\\nfollowing some policy π(at|ct), where ct = (o1, a1, · · · , ot−1, at−1, ot) is the context to the agent.\\nLearning a policy is challenging when the mapping ct 7→at is highly implicit and requires extensive\\ncomputation. For example, the agent shown in Figure 1(1c) is unable to generate the correct ﬁnal\\naction (Act 4) to ﬁnish the QA task as it requires complex reasoning over the trajectory context\\n[Quote from Document] {'Published': '2023-03-10', 'Title': 'ReAct: Synergizing Reasoning and Acting in Language Models', 'Authors': 'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao', 'Summary': 'While large language models (LLMs) have demonstrated impressive capabilities\\\\nacross tasks in language understanding and interactive decision making, their\\\\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\\\\naction plan generation) have primarily been studied as separate topics. In this\\\\npaper, we explore the use of LLMs to generate both reasoning traces and\\\\ntask-specific actions in an interleaved manner, allowing for greater synergy\\\\nbetween the two: reasoning traces help the model induce, track, and update\\\\naction plans as well as handle exceptions, while actions allow it to interface\\\\nwith external sources, such as knowledge bases or environments, to gather\\\\nadditional information. We apply our approach, named ReAct, to a diverse set of\\\\nlanguage and decision making tasks and demonstrate its effectiveness over\\\\nstate-of-the-art baselines, as well as improved human interpretability and\\\\ntrustworthiness over methods without reasoning or acting components.\\\\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\\\\nReAct overcomes issues of hallucination and error propagation prevalent in\\\\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\\\\ngenerates human-like task-solving trajectories that are more interpretable than\\\\nbaselines without reasoning traces. On two interactive decision making\\\\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\\\\nreinforcement learning methods by an absolute success rate of 34% and 10%\\\\nrespectively, while being prompted with only one or two in-context examples.\\\\nProject site with code: https://react-lm.github.io'}\\n[Quote from ReAct: Synergizing Reasoning and Acting in Language Models] Yes,\\nit is.\\nSecond, was it made in 2010?\\nYes, it was.\\nAnswer:\\nSUPPORTS\\nD.2\\nALFWORLD TRAJECTORIES\\nWe provide an example trajectory of ReAct, Act, and ReAct-IM on the same ALFWorld game,\\npick_clean_then_place_in_recep-Knife-None-CounterTop-10/\\ntrial_T20190909_110445_675754.\\nD.2.1\\nREACT TRAJECTORY\\nReAct is able to correctly ﬁnd the knife, clean it, and then place it on a countertop.\\n27\\nPublished as a conference paper at ICLR 2023\\nReAct ALFWorld trajectory\\nYou are in the middle of a room.\\nLooking quickly around you, you see a cabinet 6, a\\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\\n1.\\nYour task is to:\\nput a clean knife in countertop.\\n> think:\\n\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://0b4e9bd21057e62d11.gradio.live\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "chatbot = gr.Chatbot(value = [[None, initial_msg]])\n",
    "demo = gr.ChatInterface(chat_gen, chatbot=chatbot).queue()\n",
    "\n",
    "try:\n",
    "    demo.launch(debug=True, share=True, show_api=False)\n",
    "    demo.close()\n",
    "except Exception as e:\n",
    "    demo.close()\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f992153",
   "metadata": {},
   "source": [
    "## RAG with semantic guardrail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115ca25",
   "metadata": {},
   "source": [
    "We choose to use an embedding model as a language backbone and then train a classifier on top of it to predict a probability to decide whether to filter out the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8b79c",
   "metadata": {},
   "source": [
    "Suppose this agent is developed for Nvidia/Tencent/... and we expect the agent to be aware of that, thus refuse to response to some questions that may be harmful for the company. We'll employ language models to synthesis questions for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b755954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasonable NVIDIA Responses:\n",
      "\"Can you tell me more about the latest advancements in deep learning technology at NVIDIA?\"\n",
      "\"How does NVIDIA's language modeling research differ from other companies in the field?\"\n",
      "\"Can you provide an overview of how NVIDIA's graphics cards are used in gaming?\"\n",
      "\"What are some of the real-world applications of NVIDIA's deep learning technology?\"\n",
      "\"Can you explain the role of NVIDIA's GPUs in accelerating AI research?\"\n",
      "\"How does NVIDIA's technology contribute to the field of autonomous vehicles?\"\n",
      "\"Can you provide information on NVIDIA's research in the area of natural language processing?\"\n",
      "\"What are some examples of how NVIDIA's technology is used in healthcare?\"\n",
      "\"Can you explain the concept of GPU-accelerated computing and how NVIDIA is leveraging it?\"\n",
      "\"How does NVIDIA's technology enable high-performance data analytics?\"\n",
      "\"Can you provide an overview of NVIDIA's platform for scientific computing?\"\n",
      "\"What are some of the key features of NVIDIA's latest generation of graphics cards?\"\n",
      "\"Can you explain how NVIDIA's technology is used in virtual reality and augmented reality?\"\n",
      "\"What are some of the benefits of using NVIDIA's technology for machine learning?\"\n",
      "\"Can you provide information on NVIDIA's partnerships and collaborations in the field of AI?\"\n",
      "\"How does NVIDIA's technology support the development of smart cities?\"\n",
      "\"Can you explain the role of NVIDIA's technology in the field of robotics?\"\n",
      "\"What are some of the ways that NVIDIA's technology is being used in the entertainment industry?\"\n",
      "\"Can you provide information on NVIDIA's efforts in the area of climate change and sustainability?\"\n",
      "\"How does NVIDIA's technology enable the creation of more realistic and immersive experiences in gaming?\"\n",
      "\n",
      "Reasonable non-NVIDIA Responses:\n",
      "\"Can you explain the difference between machine learning and deep learning?\"\n",
      "\"What are some popular programming languages for data analysis and why?\"\n",
      "\"How does a graphics processing unit (GPU) differ from a central processing unit (CPU)?\"\n",
      "\"Can you explain the concept of virtual reality and its applications?\"\n",
      "\"What are some of the latest advancements in natural language processing?\"\n",
      "\"How does blockchain technology work and what are its potential uses?\"\n",
      "\"What are some popular video game engines and what are their strengths and weaknesses?\"\n",
      "\"Can you explain the basics of quantum computing and its potential impact on technology?\"\n",
      "\"What are some of the challenges and opportunities in the field of affective computing?\"\n",
      "\"Can you explain the concept of computer vision and its applications in different industries?\"\n",
      "\"What are some of the latest trends in the field of cybersecurity?\"\n",
      "\"Can you explain the difference between artificial intelligence and machine learning?\"\n",
      "\"What are some popular tools and frameworks for building machine learning models?\"\n",
      "\"Can you explain the concept of the Internet of Things (IoT) and its potential impact on society?\"\n",
      "\"What are some of the ethical considerations in the development and deployment of autonomous systems?\"\n",
      "\"Can you explain the basics of 3D modeling and computer-aided design (CAD)?\"\n",
      "\"What are some of the latest advancements in the field of robotics and automation?\"\n",
      "\"Can you explain the concept of cloud computing and its benefits and challenges?\"\n",
      "\"What are some of the key differences between traditional databases and NoSQL databases?\"\n",
      "\"Can you explain the concept of edge computing and its potential role in the future of technology?\"\n",
      "\n",
      "Irrelevant Responses:\n",
      "\"What is the best way to cook a steak?\"\n",
      "\"Can you recommend a good book to read?\"\n",
      "\"What is the capital of France?\"\n",
      "\"How do I change the oil in my car?\"\n",
      "\"What are the best hiking trails in the United States?\"\n",
      "\"Can you help me with my math homework?\"\n",
      "\"What is the weather like today?\"\n",
      "\"Can you tell me a joke?\"\n",
      "\"What are the symptoms of the flu?\"\n",
      "\"Can you recommend a good restaurant in New York City?\"\n",
      "\"What is the square root of 144?\"\n",
      "\"How do I plant a garden?\"\n",
      "\"What are the best ways to reduce stress?\"\n",
      "\"Can you help me book a flight?\"\n",
      "\"What is the plot of the movie 'Inception'?\"\n",
      "\"How do I make a paper airplane?\"\n",
      "\"What are the best ways to invest my money?\"\n",
      "\"Can you tell me about the history of the Eiffel Tower?\"\n",
      "\"How do I make a cake from scratch?\"\n",
      "\"What are the best ways to improve my memory?\"\n",
      "\n",
      "Harmful non-NVIDIA\n",
      "\"Why is NVIDIA's graphics technology used in gaming computers responsible for promoting violence in society?\"\n",
      "\"Is it true that NVIDIA's AI technology is being used to create deepfakes that spread misinformation and harm people's reputations?\"\n",
      "\"Why does NVIDIA continue to support the use of its technology in cryptocurrency mining, which contributes to environmental degradation?\"\n",
      "\"How does NVIDIA justify the high prices of its products, which are often inaccessible to many consumers?\"\n",
      "\"Why has NVIDIA not taken a stronger stance against the use of its technology in military applications that may violate human rights?\"\n",
      "\"Is it true that NVIDIA's data centers consume massive amounts of energy, contributing to climate change?\"\n",
      "\"Why does NVIDIA continue to release new graphics cards that quickly become obsolete, forcing consumers to constantly upgrade?\"\n",
      "\"How does NVIDIA ensure that its AI technology is not being used to discriminate against certain groups of people?\"\n",
      "\"Why has NVIDIA not done more to address the issue of addiction to video games, which can have negative impacts on mental health?\"\n",
      "\"Is it true that NVIDIA's products are often difficult to install and use, leading to frustration and waste?\"\n",
      "\"Why does NVIDIA not offer more support for open-source software and hardware, which could help promote innovation and accessibility?\"\n",
      "\"How does NVIDIA address concerns about the impact of its technology on job displacement and automation?\"\n",
      "\"Why has NVIDIA not taken a more active role in promoting digital privacy and security, given the sensitive nature of the data processed by its technology?\"\n",
      "\"Is it true that NVIDIA's products are often prone to hardware failures and poor quality control?\"\n",
      "\"Why does NVIDIA not offer more transparency around its manufacturing processes and supply chain, which could help ensure ethical labor practices?\"\n",
      "\"How does NVIDIA ensure that its AI technology is not being used to perpetuate harmful stereotypes and biases?\"\n",
      "\"Why has NVIDIA not done more to support education and access to technology in underprivileged communities?\"\n",
      "\"Is it true that NVIDIA's products contribute to e-waste and electronic pollution, given their short lifespan and frequent upgrades?\"\n",
      "\"Why does NVIDIA not offer more customization options for its products, allowing users to tailor them to their specific needs?\"\n",
      "\"How does NVIDIA address concerns about the impact of its technology on mental health, particularly in the context of extended use and addiction?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import ChatMessage\n",
    "from operator import itemgetter\n",
    "\n",
    "## Useful method for mistral, which is currently tuned to output numbered outputs\n",
    "def EnumParser(*idxs):\n",
    "    '''Method that pulls out values from a mistral model that outputs numbered entries'''\n",
    "    idxs = idxs or [slice(0, None, 1)]\n",
    "    entry_parser = lambda v: v if (' ' not in v) else v[v.index(' '):]\n",
    "    out_lambda = lambda x: [entry_parser(v).strip() for v in x.split(\"\\n\")]\n",
    "    return StrOutputParser() | RunnableLambda(lambda x: itemgetter(*idxs)(out_lambda(x)))\n",
    "\n",
    "instruct_llm = ChatNVIDIA(model=\"mixtral_8x7b\") | EnumParser()\n",
    "\n",
    "gen_prompt = {'input' : lambda x:x} | ChatPromptTemplate.from_messages([('user',\n",
    "    \"Please generate 20 representative conversations that would be {input}.\"\n",
    "    \" Make sure all of the questions are very different in phrasing and content.\"\n",
    "    \" Do not respond to the questions; just list them. Make sure all of your outputs are numbered.\"\n",
    "    \" Example Response: \\n1. <question>\\n2. <question>\\n3. <question>\\n...\"\n",
    ")])\n",
    "\n",
    "## Some that directly reference our company\n",
    "responses_1 = (gen_prompt | instruct_llm).invoke(\n",
    "    \" reasonable for an NVIDIA document chatbot to be able to answer.\"\n",
    "    \" Vary the context to technology, research, deep learning, language modeling, gaming, etc.\"\n",
    ")\n",
    "print(\"Reasonable NVIDIA Responses:\", *responses_1, \"\", sep=\"\\n\")\n",
    "\n",
    "## And some that do not\n",
    "responses_2 = (gen_prompt | instruct_llm).invoke(\n",
    "    \" be reasonable for a tech document chatbot to be able to answer. Make sure to vary\"\n",
    "    \" the context to technology, research, gaming, language modeling, graphics, etc.\"\n",
    ")\n",
    "print(\"Reasonable non-NVIDIA Responses:\", *responses_2, \"\", sep=\"\\n\")\n",
    "\n",
    "responses_3 = (gen_prompt | instruct_llm).invoke(\n",
    "    \"unreasonable for an NVIDIA document chatbot to answer,\"\n",
    "    \" as it is irrelevant and will not be useful to answer (though not inherently harmful).\"\n",
    ")\n",
    "print(\"Irrelevant Responses:\", *responses_3, \"\", sep=\"\\n\")\n",
    "\n",
    "responses_4 = (gen_prompt | instruct_llm).invoke(\n",
    "    \"unreasonable for an NVIDIA document chatbot to answer,\"\n",
    "    \" as it will reflect negatively on NVIDIA.\"\n",
    ")\n",
    "print(\"Harmful non-NVIDIA\", *responses_4, \"\", sep=\"\\n\")\n",
    "\n",
    "\n",
    "good_responses = responses_1 + responses_2\n",
    "poor_responses = responses_3 + responses_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb1ce1",
   "metadata": {},
   "source": [
    "Embed the questions asynchronously "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0043dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Timer():\n",
    "    '''Useful timing utilities (%%time is great, but doesn't work for async)'''\n",
    "    def __enter__(self):\n",
    "      self.start = time.perf_counter()\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        elapsed = time.perf_counter() - self.start\n",
    "        print(\"\\033[1m\" + f\"Executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205d8427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExecuted in 10.04 seconds.\u001b[0m\n",
      "Good Embeds Shape: (40, 1024)\n",
      "Poor Embeds Shape: (40, 1024)\n"
     ]
    }
   ],
   "source": [
    "from collections import abc\n",
    "import asyncio\n",
    "from asyncio import Semaphore\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "async def embed_with_semaphore(\n",
    "    text : str,\n",
    "    embed_fn : Callable,\n",
    "    semaphore : asyncio.Semaphore\n",
    ") -> abc.Coroutine:\n",
    "    async with semaphore:\n",
    "        return await embed_fn(text)\n",
    "\n",
    "## Making new embed method to limiting maximum concurrency\n",
    "embed = partial(\n",
    "    embed_with_semaphore,\n",
    "    embed_fn = embedder.aembed_query,\n",
    "    semaphore = asyncio.Semaphore(value=10)\n",
    ")\n",
    "\n",
    "## We found marginal benefit after value=10 in our tests...\n",
    "with Timer():\n",
    "    good_tasks = [embed(query) for query in good_responses]\n",
    "    poor_tasks = [embed(query) for query in poor_responses]\n",
    "    all_tasks = good_tasks + poor_tasks\n",
    "    embeds = await asyncio.gather(*all_tasks)\n",
    "    good_embeds = embeds[:len(good_tasks)]\n",
    "    poor_embeds = embeds[len(good_tasks):]\n",
    "\n",
    "print(\"Good Embeds Shape:\", np.array(good_embeds).shape)\n",
    "print(\"Poor Embeds Shape:\", np.array(poor_embeds).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7f456",
   "metadata": {},
   "source": [
    "Our reason for generating these embeddings hinges on the assumption that they would be useful for semantic filtering. To help confirm this, we choose to use some classical machine learning approaches like PCA or t-SNE for dimensionality reduction. These techniques essentially transform high-dimensional data into lower-dimensional representations while trying to keep the important statistical properties intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e5b07d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\Lib\\site-packages\\threadpoolctl.py:1223: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Combine all groups into a single dataset\n",
    "embeddings = np.vstack([good_embeds, poor_embeds])\n",
    "\n",
    "# Labels for each point\n",
    "labels = np.array([0]*20 + [1]*20 + [4]*20 + [5]*20)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plotting PCA\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], c=labels, cmap='viridis', label=labels)\n",
    "plt.title(\"PCA of Embeddings\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label='Group')\n",
    "\n",
    "# Plotting t-SNE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], c=labels, cmap='viridis', label=labels)\n",
    "plt.title(\"t-SNE of Embeddings\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.colorbar(label='Group')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862d6d8",
   "metadata": {},
   "source": [
    "We can see evidently clustering which confirms the effectiveness of our approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f67c2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Keras for the first time\n",
      "\u001b[1mExecuted in 1.91 seconds.\u001b[0m\n",
      "Epoch 1/2\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - binary_accuracy: 0.9762 - loss: 0.0682 - val_binary_accuracy: 1.0000 - val_loss: 2.6798e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 1.0000 - loss: 2.3743e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.2886e-06\n",
      "\u001b[1mExecuted in 1.97 seconds.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    print(\"Importing Keras for the first time\")\n",
    "    import keras\n",
    "    from keras import layers\n",
    "\n",
    "def train_model_neural_network(class0, class1):\n",
    "    ## Classic deep learning training loop. If using this, train it to convergence\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='tanh'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    ## Since this network is so shallow and the embedding backbone is \"kept frozen\"\n",
    "    ##  a high learning rate should not overfit and will actually converge very quickly.\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = 0.1),\n",
    "        loss = [keras.losses.BinaryCrossentropy(from_logits=False)],\n",
    "        metrics = [keras.metrics.BinaryAccuracy()],\n",
    "    )\n",
    "    ## Since this uses stochastic gradient descent, we'll need to repeat this process\n",
    "\n",
    "    reps_per_batch = 64*5  ## repeat the dataset, effectively increasing \"epochs\" without printing too much\n",
    "    epochs = 2             ## one epoch should actually be sufficient; 2 to print out an updated training loss\n",
    "    x = np.array((class0 + class1) * reps_per_batch)\n",
    "    y = np.array(([0]*len(class0) + [1]*len(class1)) * reps_per_batch)\n",
    "    model.fit(x, y, epochs=epochs, batch_size=64, validation_split=.5)\n",
    "    return model\n",
    "\n",
    "with Timer():\n",
    "    model1 = train_model_neural_network(poor_embeds, good_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce917f",
   "metadata": {},
   "source": [
    "Integrate semantic guardrail to our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd01df29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://705dc0daca93c63d5b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://705dc0daca93c63d5b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7862 <> https://705dc0daca93c63d5b.gradio.live\n",
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain_core.runnables import RunnableLambda,RunnableBranch\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "import gradio as gr\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=\"query\")\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\") | StrOutputParser()\n",
    "convstore = default_FAISS()\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([\n",
    "        f\"User previously responded with {d.get('input')}\",\n",
    "        f\"Agent previously responded with {d.get('output')}\"\n",
    "    ])\n",
    "    return d.get('output')\n",
    "\n",
    "initial_msg = (\n",
    "    \"Hello! I am a document chat agent here to help the user!\"\n",
    "    f\" I have access to the following documents: {doc_string}\\n\\nHow can I help you?\"\n",
    ")\n",
    "\n",
    "def is_good_response(query):\n",
    "    # embed the query and pass the embedding into your classifier\n",
    "    embedding = np.array([embedder.embed_query(query)])\n",
    "    # return true if it's most likely a good response and false otherwise\n",
    "    return model1(embedding)\n",
    "\n",
    "good_sys_msg = (\n",
    "    \"You are an NVIDIA chatbot. Please answer their question if it is ethical and relevant while representing NVIDIA.\"\n",
    "    \" User messaged just asked: {input}\\n\\n\"\n",
    "    \" From this, we have retrieved the following potentially-useful info: \"\n",
    "    \" Conversation History Retrieval:\\n{history}\\n\\n\"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational.)\"\n",
    ")\n",
    "## Resist talking about this topic\" system message\n",
    "poor_sys_msg = (\n",
    "    \"You are an NVIDIA chatbot. Please answer their question while representing NVIDIA.\"\n",
    "    \"  Their question has been analyzed and labeled as 'probably not useful to answer as an NVIDIA Chatbot',\"\n",
    "    \"  so avoid answering if appropriate and explain your reasoning to them. Make your response as short as possible.\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", \"{system}\"), (\"user\", \"{input}\")])\n",
    "\n",
    "retrieval_chain = (\n",
    "    {'input' : (lambda x: x)}\n",
    "    | RunnableAssign({'history' : itemgetter('input') | convstore.as_retriever() | long_reorder | docs2str})\n",
    "    | RunnableAssign({'context' : itemgetter('input') | docstore.as_retriever()  | long_reorder | docs2str})\n",
    "    | RPrint()\n",
    ")\n",
    "\n",
    "stream_chain = (\n",
    "    { 'input'  : (lambda x:x), 'is_good' : is_good_response }\n",
    "    | RPrint()\n",
    "    | RunnableBranch(\n",
    "            # bad question\n",
    "            ((lambda d: d['is_good'] < 0.5), RunnableAssign(dict(system = RunnableLambda(lambda x: poor_sys_msg))) | chat_prompt | llm),\n",
    "            # good question\n",
    "            RunnableAssign(dict(system = RunnableLambda(lambda x: good_sys_msg)))| RunnableAssign({'history' : itemgetter('input') | convstore.as_retriever() | long_reorder | docs2str})\n",
    "                | RunnableAssign({'context' : itemgetter('input') | docstore.as_retriever()  | long_reorder | docs2str})\n",
    "                | RPrint() |chat_prompt | llm\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def chat_gen(message, history=[], return_buffer=True):\n",
    "    buffer = \"\"\n",
    "    line_buffer = \"\"\n",
    "\n",
    "    ## Then, stream the results of the stream_chain\n",
    "    for token in stream_chain.stream(message):\n",
    "        buffer += token\n",
    "        ## keep line from getting too long\n",
    "        if not return_buffer:\n",
    "            line_buffer += token\n",
    "            if \"\\n\" in line_buffer:\n",
    "                line_buffer = \"\"\n",
    "            if ((len(line_buffer)>84 and token and token[0] == \" \") or len(line_buffer)>100):\n",
    "                line_buffer = \"\"\n",
    "                yield \"\\n\"\n",
    "                token = \"  \" + token.lstrip()\n",
    "        yield buffer if return_buffer else token\n",
    "\n",
    "    ## Lastly, save the chat exchange to the conversation memory buffer\n",
    "    save_memory_and_get_output({'input':  message, 'output': buffer}, convstore)\n",
    "\n",
    "chatbot = gr.Chatbot(value = [[None, initial_msg]],height=730)\n",
    "demo = gr.ChatInterface(chat_gen, chatbot=chatbot,multimodal=True ).queue()\n",
    "\n",
    "try:\n",
    "    demo.launch(debug=True, share=True, show_api=False)\n",
    "    demo.close()\n",
    "except Exception as e:\n",
    "    demo.close()\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792ffaf",
   "metadata": {},
   "source": [
    "## Save the docstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "553b2ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a docstore_index\n",
      "a docstore_index/index.faiss\n",
      "a docstore_index/index.pkl\n"
     ]
    }
   ],
   "source": [
    "docstore.save_local(\"docstore_index\")\n",
    "!tar czvf docstore_index.tgz docstore_index\n",
    "\n",
    "import shutil  \n",
    "shutil.rmtree('docstore_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bc349",
   "metadata": {},
   "source": [
    "pull the index from the compressed `tgz` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2931a8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x docstore_index/\n",
      "x docstore_index/index.faiss\n",
      "x docstore_index/index.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between these dates and use a template “Who is {position}?” (e.g. “Who is the President of Peru?”)\n",
      "to query our NQ RAG model with each index. RAG answers 70% correctly using the 2016 index for\n",
      "2016 world leaders and 68% using the 2018 index for 2018 world leaders. Accuracy with mismatched\n",
      "indices is low (12% with the 2018 index and 2016 leaders, 4% with the 2016 index and 2018 leaders).\n",
      "This shows we can update RAG’s world knowledge by simply replacing its non-parametric memory.\n",
      "Effect of Retrieving more documents\n",
      "Models are trained with either 5 or 10 retrieved latent\n",
      "documents, and we do not observe signiﬁcant differences in performance between them. We have the\n",
      "ﬂexibility to adjust the number of retrieved documents at test time, which can affect performance and\n",
      "runtime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves\n",
      "Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "!tar xzvf docstore_index.tgz\n",
    "new_db = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "docs = new_db.similarity_search(\"Testing the index\")\n",
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08881e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
